{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow==2.5.0 --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as psy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import statistics\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establish connection with the PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_host = \"localhost\"\n",
    "database_name = \"dbl_data_challenge\"\n",
    "database_user = \"admin\"\n",
    "database_pass = \"vZtbqKNXGz27cQCH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = psy.connect(\n",
    "    host = database_host,\n",
    "    database = database_name,\n",
    "    user = database_user,\n",
    "    password = database_pass\n",
    ")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a neural network to be able to evaluate sentiment of tweets / conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggel = pd.read_csv('Tweets.csv')\n",
    "df_kaggel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_processing(text):\n",
    "    stpword = stopwords.words('english')\n",
    "    no_punctuation = [char for char in text if char not in string.punctuation]\n",
    "    no_punctuation = ''.join(no_punctuation)\n",
    "    return ' '.join([word for word in no_punctuation.split() if word.lower() not in stpword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_kaggel.copy()\n",
    "df = df[['text', 'airline_sentiment']]\n",
    "df['text'] = df['text'].apply(get_text_processing)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df['airline_sentiment'])\n",
    "df_ranked = df.drop(['airline_sentiment'], axis=1, inplace=True)\n",
    "df_complete = pd.concat([df, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, test and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_complete[\"text\"].values\n",
    "y = df_complete.drop(\"text\", axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test1 = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test1 = tfidf.transform(X_test1)\n",
    "X_train = X_train.toarray()\n",
    "X_test1 = X_test1.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=12673, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=4000, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=500, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=3, activation=\"softmax\"))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=256,\n",
    "    epochs=2,\n",
    "    validation_data=(X_test1, y_test),\n",
    "    verbose=1,\n",
    "    callbacks=early_stop,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = model.evaluate(X_test1, y_test, batch_size=64, verbose=1)\n",
    "print(\"Test accuracy:\", model_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggel['text'] = df_kaggel['text'].apply(get_text_processing)\n",
    "test_ds  = df_kaggel['text']\n",
    "test_feature = vect.transform(np.array(test_ds.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(test_feature)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggel['our_sent'] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rating_categories = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "df_kaggel['our_sent'] = df_kaggel['our_sent'].map(dict_rating_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling and quick sentiment functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_model(text, df):\n",
    "    \"\"\"\n",
    "    Text argument comes from the df passed to the function\n",
    "    \"\"\"\n",
    "    text = text.apply(get_text_processing)\n",
    "    test_ds  = text\n",
    "    test_feature = vect.transform(np.array(test_ds.ravel()))\n",
    "    predict = model.predict(test_feature)\n",
    "    predict = np.argmax(predict, axis=1)\n",
    "    df['our_sent'] = predict\n",
    "    dict_rating_categories = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "    df['our_sent'] = df['our_sent'].map(dict_rating_categories)\n",
    "    return df\n",
    "\n",
    "\n",
    "def quick_sentiment(text):\n",
    "    \"\"\"\n",
    "    Returns sentiment for 1-2 tweets\n",
    "    \"\"\"\n",
    "    text = pd.Series(text)\n",
    "    #model predictions\n",
    "    text = text.apply(get_text_processing)\n",
    "    test_ds  = text\n",
    "    test_feature = vect.transform(np.array(test_ds.ravel()))\n",
    "    predict = model.predict(test_feature)\n",
    "    predict = np.argmax(predict, axis=1)\n",
    "    dict_rating_categories = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "    predict = np.vectorize(dict_rating_categories.__getitem__)(predict)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model(df_kaggel[\"text\"], df_kaggel)\n",
    "\n",
    "# true: positive, ours: negative\n",
    "pos_is_neg = len(df_kaggel[(df_kaggel[\"airline_sentiment\"] == \"positive\") & (df_kaggel[\"our_sent\"] == \"negative\")])\n",
    "# true: positive, ours: neutral\n",
    "pos_is_neu = len(df_kaggel[(df_kaggel[\"airline_sentiment\"] == \"positive\") & (df_kaggel[\"our_sent\"] == \"neutral\")])\n",
    "# true: neutral, ours: positive\n",
    "neu_is_pos = len(df_kaggel[(df_kaggel[\"airline_sentiment\"] == \"neutral\") & (df_kaggel[\"our_sent\"] == \"positive\")])\n",
    "# true: neutral, ours: negative\n",
    "neu_is_neg = len(df_kaggel[(df_kaggel[\"airline_sentiment\"] == \"neutral\") & (df_kaggel[\"our_sent\"] == \"negative\")])\n",
    "# true: negative, ours: neutral\n",
    "neg_is_neu = len(df_kaggel[(df_kaggel[\"airline_sentiment\"] == \"negative\") & (df_kaggel[\"our_sent\"] == \"neutral\")])\n",
    "# true: negative, ours: positive\n",
    "neg_is_pos = len(df_kaggel[(df_kaggel[\"airline_sentiment\"] == \"negative\") & (df_kaggel[\"our_sent\"] == \"positive\")])\n",
    "\n",
    "pos_is_neg, pos_is_neu, neu_is_pos, neu_is_neg, neg_is_neu, neg_is_pos\n",
    "worse_sentiment = pos_is_neg + pos_is_neu + neu_is_neg\n",
    "better_sentiment = neu_is_pos + neg_is_neu + neg_is_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worse_sentiment, better_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing conversations from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "    SELECT tweets.full_text, tweets.user_id_str, tweets.timestamp_ms, aba_groups.id_str, aba_groups.aba_level, aba_groups.aba_id, aba_groups.conversation_id\n",
    "    FROM tweets, aba_groups\n",
    "    WHERE tweets.id_str = aba_groups.id_str\n",
    "    ORDER BY aba_groups.aba_id, aba_groups.aba_level\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating sentiment for ABA conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aba = pd.DataFrame(columns=['full_text', 'user_id_str','timestamp_ms', 'id_str', 'aba_level', 'aba_id', 'conversation_id'], data=cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_aba_sent = our_model(df_aba['full_text'], df_aba)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aba_sent = pd.read_csv('aba_sentiment.csv')\n",
    "\n",
    "dict_rating_categories_2 = {'negative':-1, 'neutral':0, 'positive':1}\n",
    "df_aba_sent['our_sent'] = df_aba_sent['our_sent'].map(dict_rating_categories_2)\n",
    "\n",
    "df_aba_sent = df_aba_sent.drop(['Unnamed: 0'],axis=1)\n",
    "df_aba_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_list=[]\n",
    "\n",
    "for aba_id, data in df_aba_sent.groupby(\"aba_id\"): \n",
    "    aba_group = df_aba_sent[df_aba_sent[\"aba_id\"] == aba_id]\n",
    "    \n",
    "    for level, row in aba_group.groupby(\"aba_level\"): \n",
    "        if level==1:\n",
    "            sent_1 = float(row['our_sent'])\n",
    "        elif level==3:\n",
    "            sent_3 = float(statistics.mean(row['our_sent']))\n",
    "         \n",
    "\n",
    "    if sent_1 == -1:\n",
    "        if sent_3 < -.5:\n",
    "            change_list.append('no_change')\n",
    "        elif -.5 <= sent_3 <= 0:\n",
    "            change_list.append('minor_positive_change')\n",
    "        elif sent_3 > 0:\n",
    "            change_list.append('positive_change')\n",
    "\n",
    "    if sent_1 == 1:\n",
    "        if 0 <= sent_3 <= .5:\n",
    "            change_list.append('minor_negative_change')\n",
    "        elif sent_3 < 0:\n",
    "            change_list.append('negative_change')\n",
    "        elif sent_3 > .5:\n",
    "            change_list.append('no_change')\n",
    "\n",
    "    if sent_1 == 0:\n",
    "        if .34 < sent_3 < .67: \n",
    "            change_list.append('minor_positive_change')\n",
    "        elif -.34 < sent_3 < -.67:\n",
    "            change_list.append('minor_negative_change')\n",
    "        elif -.34 <= sent_3 <= .34:\n",
    "            change_list.append('no_change')\n",
    "        elif sent_3 >= .67:\n",
    "            change_list.append('positive_change')\n",
    "        elif sent_3 <= .67:\n",
    "            change_list.append('negative_change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict_rating_categories_2_reverse = {-1:'negative', 0:'neutral', 1:'positive',\n",
    "    'positive_change':'positive_change','negative_change':'negative_change','no_change':'no_change','minor_positive_change':'minor_positive_change','minor_negative_change':'minor_negative_change'}\n",
    "\n",
    "df_aba_sent.loc[df_aba_sent['aba_level']==2,'our_sent'] = change_list\n",
    "\n",
    "\n",
    "df_aba_sent['our_sent'] = df_aba_sent['our_sent'].map(dict_rating_categories_2_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_aba_sent.to_csv('df_aba_sent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating sentiment for root conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "    SELECT tweets.full_text, tweets.timestamp_ms, tweets.user_id_str, root_groups.id_str, root_groups.root_level, root_groups.root_id\n",
    "    FROM tweets, root_groups\n",
    "    WHERE tweets.id_str = root_groups.id_str\n",
    "    ORDER BY root_groups.root_id, root_groups.root_level\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root = pd.DataFrame(columns=['full_text','timestamp_ms', 'user_id_str', 'id_str', 'root_level', 'root_id'], data=cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_root_sent = our_model(df_root['full_text'], df_root)\n",
    "\n",
    "print(\"This took: \"+str(time.time() - start)+\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the dataframe to local storage in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root_sent.to_csv('df_root_sent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
