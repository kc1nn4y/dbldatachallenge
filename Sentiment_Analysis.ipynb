{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow==2.5.0 --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Goshko\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2 as psy\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import statistics\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training up a neural network to evaluate sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggel = pd.read_csv('Tweets.csv')\n",
    "df_kaggel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text preprocesing\n",
    "def get_text_processing(text):\n",
    "    stpword = stopwords.words('english')\n",
    "    no_punctuation = [char for char in text if char not in string.punctuation]\n",
    "    no_punctuation = ''.join(no_punctuation)\n",
    "    return ' '.join([word for word in no_punctuation.split() if word.lower() not in stpword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VirginAmerica dhepburn said</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VirginAmerica plus youve added commercials exp...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VirginAmerica didnt today Must mean need take ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VirginAmerica really aggressive blast obnoxiou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VirginAmerica really big bad thing</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0                        VirginAmerica dhepburn said           neutral\n",
       "1  VirginAmerica plus youve added commercials exp...          positive\n",
       "2  VirginAmerica didnt today Must mean need take ...           neutral\n",
       "3  VirginAmerica really aggressive blast obnoxiou...          negative\n",
       "4                 VirginAmerica really big bad thing          negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_kaggel.copy()\n",
    "df = df[['text', 'airline_sentiment']]\n",
    "df['text'] = df['text'].apply(get_text_processing)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummies\n",
    "df_dummies = pd.get_dummies(df['airline_sentiment'])\n",
    "df_ranked = df.drop(['airline_sentiment'], axis=1, inplace=True)\n",
    "df_complete = pd.concat([df, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train, test split\n",
    "\n",
    "X = df_complete[\"text\"].values\n",
    "y = df_complete.drop(\"text\", axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization\n",
    "\n",
    "vect = CountVectorizer()\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test1 = vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test1 = tfidf.transform(X_test1)\n",
    "X_train = X_train.toarray()\n",
    "X_test1 = X_test1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=12673, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=4000, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=500, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=3, activation=\"softmax\"))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "41/41 [==============================] - 112s 3s/step - loss: 0.7061 - accuracy: 0.7020 - val_loss: 0.5427 - val_accuracy: 0.7937\n",
      "Epoch 2/2\n",
      "41/41 [==============================] - 112s 3s/step - loss: 0.2815 - accuracy: 0.9030 - val_loss: 0.5689 - val_accuracy: 0.7962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x186838d57c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the model\n",
    "\n",
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=256,\n",
    "    epochs=2,\n",
    "    validation_data=(X_test1, y_test),\n",
    "    verbose=1,\n",
    "    callbacks=early_stop,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 15s 222ms/step - loss: 0.5689 - accuracy: 0.7962\n",
      "Test accuracy: 0.7962204217910767\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "\n",
    "model_score = model.evaluate(X_test1, y_test, batch_size=64, verbose=1)\n",
    "print(\"Test accuracy:\", model_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model predictions\n",
    "df_kaggel['text'] = df_kaggel['text'].apply(get_text_processing)\n",
    "test_ds  = df_kaggel['text']\n",
    "test_feature = vect.transform(np.array(test_ds.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict(test_feature)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggel['our_sent'] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rating_categories = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "df_kaggel['our_sent'] = df_kaggel['our_sent'].map(dict_rating_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_model(text, df):\n",
    "    \"\"\"text argument comes from the df passed to the function\"\"\"\n",
    "    \n",
    "    \n",
    "    #text = df['text']\n",
    "    #model predictions\n",
    "    text = text.apply(get_text_processing)\n",
    "    test_ds  = text\n",
    "    test_feature = vect.transform(np.array(test_ds.ravel()))\n",
    "\n",
    "    predict = model.predict(test_feature)\n",
    "    predict = np.argmax(predict, axis=1)\n",
    "\n",
    "    df['our_sent'] = predict\n",
    "\n",
    "    dict_rating_categories = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "    df['our_sent'] = df['our_sent'].map(dict_rating_categories)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def quick_sentiment(text):\n",
    "    \"\"\"Returns sentiment for 1-2 tweets.\"\"\"\n",
    "    \n",
    "    text = pd.Series(text)\n",
    "    \n",
    "    #model predictions\n",
    "    text = text.apply(get_text_processing)\n",
    "    test_ds  = text\n",
    "    test_feature = vect.transform(np.array(test_ds.ravel()))\n",
    "\n",
    "    predict = model.predict(test_feature)\n",
    "    predict = np.argmax(predict, axis=1)\n",
    "    \n",
    "    dict_rating_categories = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "    predict = np.vectorize(dict_rating_categories.__getitem__)(predict)\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model(df_kaggel[\"text\"], df_kaggel)\n",
    "\n",
    "# true: positive, ours: negative\n",
    "pos_is_neg = len(df_kaggel[(df_kaggel[\"airline_sentiment\"] == \"positive\") & (df_kaggel[\"our_sent\"] == \"negative\")])\n",
    "# true: positive, ours: neutral\n",
    "pos_is_neu = len(df_kaggel[(df_kaggel[\"airline_sentiment\"] == \"positive\") & (df_kaggel[\"our_sent\"] == \"neutral\")])\n",
    "# true: neutral, ours: positive\n",
    "neu_is_pos = len(df_kaggel[(df_kaggel[\"airline_sentiment\"] == \"neutral\") & (df_kaggel[\"our_sent\"] == \"positive\")])\n",
    "# true: neutral, ours: negative\n",
    "neu_is_neg = len(df_kaggel[(df_kaggel[\"airline_sentiment\"] == \"neutral\") & (df_kaggel[\"our_sent\"] == \"negative\")])\n",
    "# true: negative, ours: neutral\n",
    "neg_is_neu = len(df_kaggel[(df_kaggel[\"airline_sentiment\"] == \"negative\") & (df_kaggel[\"our_sent\"] == \"neutral\")])\n",
    "# true: negative, ours: positive\n",
    "neg_is_pos = len(df_kaggel[(df_kaggel[\"airline_sentiment\"] == \"negative\") & (df_kaggel[\"our_sent\"] == \"positive\")])\n",
    "\n",
    "pos_is_neg, pos_is_neu, neu_is_pos, neu_is_neg, neg_is_neu, neg_is_pos\n",
    "worse_sentiment = pos_is_neg + pos_is_neu + neu_is_neg\n",
    "better_sentiment = neu_is_pos + neg_is_neu + neg_is_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1002, 351)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worse_sentiment,better_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating convos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_host = \"localhost\"\n",
    "database_name = \"dbl_data_challenge\"\n",
    "database_user = \"admin\"\n",
    "database_pass = \"vZtbqKNXGz27cQCH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = psy.connect(\n",
    "    host = database_host,\n",
    "    database = database_name,\n",
    "    user = database_user,\n",
    "    password = database_pass\n",
    ")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "    SELECT tweetv2.full_text, tweetv2.user_id_str, tweetv2.timestamp_ms, aba_groups.id_str, aba_groups.aba_level, aba_groups.aba_id, aba_groups.conversation_id\n",
    "    FROM tweetv2, aba_groups\n",
    "    WHERE tweetv2.id_str = aba_groups.id_str\n",
    "    ORDER BY aba_groups.aba_id, aba_groups.aba_level\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating sentiment for ABA conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aba = pd.DataFrame(columns=['full_text', 'user_id_str','timestamp_ms', 'id_str', 'aba_level', 'aba_id', 'conversation_id'], data=cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_aba_sent = our_model(df_aba['full_text'], df_aba)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aba_sent = pd.read_csv('aba_sentiment.csv')\n",
    "\n",
    "dict_rating_categories_2 = {'negative':-1, 'neutral':0, 'positive':1}\n",
    "df_aba_sent['our_sent'] = df_aba_sent['our_sent'].map(dict_rating_categories_2)\n",
    "\n",
    "df_aba_sent = df_aba_sent.drop(['Unnamed: 0'],axis=1)\n",
    "df_aba_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_list=[]\n",
    "\n",
    "for aba_id, data in df_aba_sent.groupby(\"aba_id\"): \n",
    "    aba_group = df_aba_sent[df_aba_sent[\"aba_id\"] == aba_id]\n",
    "    \n",
    "    for level, row in aba_group.groupby(\"aba_level\"): \n",
    "        if level==1:\n",
    "            sent_1 = float(row['our_sent'])\n",
    "        elif level==3:\n",
    "            sent_3 = float(statistics.mean(row['our_sent']))\n",
    "         \n",
    "\n",
    "    if sent_1 == -1:\n",
    "        if sent_3 < -.5:\n",
    "            change_list.append('no_change')\n",
    "        elif -.5 <= sent_3 <= 0:\n",
    "            change_list.append('minor_positive_change')\n",
    "        elif sent_3 > 0:\n",
    "            change_list.append('positive_change')\n",
    "\n",
    "    if sent_1 == 1:\n",
    "        if 0 <= sent_3 <= .5:\n",
    "            change_list.append('minor_negative_change')\n",
    "        elif sent_3 < 0:\n",
    "            change_list.append('negative_change')\n",
    "        elif sent_3 > .5:\n",
    "            change_list.append('no_change')\n",
    "\n",
    "    if sent_1 == 0:\n",
    "        if .34 < sent_3 < .67: \n",
    "            change_list.append('minor_positive_change')\n",
    "        elif -.34 < sent_3 < -.67:\n",
    "            change_list.append('minor_negative_change')\n",
    "        elif -.34 <= sent_3 <= .34:\n",
    "            change_list.append('no_change')\n",
    "        elif sent_3 >= .67:\n",
    "            change_list.append('positive_change')\n",
    "        elif sent_3 <= .67:\n",
    "            change_list.append('negative_change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict_rating_categories_2_reverse = {-1:'negative', 0:'neutral', 1:'positive',\n",
    "    'positive_change':'positive_change','negative_change':'negative_change','no_change':'no_change','minor_positive_change':'minor_positive_change','minor_negative_change':'minor_negative_change'}\n",
    "\n",
    "df_aba_sent.loc[df_aba_sent['aba_level']==2,'our_sent'] = change_list\n",
    "\n",
    "\n",
    "df_aba_sent['our_sent'] = df_aba_sent['our_sent'].map(dict_rating_categories_2_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_aba_sent.to_csv('df_aba_sent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating sentiment for root conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "    SELECT tweetv2.full_text, tweetv2.timestamp_ms, tweetv2.user_id_str, root_groups.id_str, root_groups.root_level, root_groups.root_id\n",
    "    FROM tweetv2, root_groups\n",
    "    WHERE tweetv2.id_str = root_groups.id_str\n",
    "    ORDER BY root_groups.root_id, root_groups.root_level\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root = pd.DataFrame(columns=['full_text','timestamp_ms', 'user_id_str', 'id_str', 'root_level', 'root_id'], data=cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_root_sent = our_model(df_root['full_text'], df_root)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root_sent.to_csv('df_root_sent.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
