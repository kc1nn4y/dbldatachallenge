{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow==2.5.0 --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as psy\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import statistics\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training up a neural network to evaluate sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggel = pd.read_csv('Tweets.csv')\n",
    "df_kaggel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment analysis preprocessing\n",
    "\n",
    "df_positive = df_kaggel[df_kaggel['airline_sentiment'] == 'positive']\n",
    "df_neutral = df_kaggel[df_kaggel['airline_sentiment'] == 'neutral']\n",
    "df_negative = df_kaggel[df_kaggel['airline_sentiment'] == 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling datasets\n",
    "df_neutral_over = df_neutral.sample(8000, replace=True)\n",
    "df_negative_over = df_negative.sample(8000, replace=True)\n",
    "df = pd.concat([df_positive, df_neutral_over, df_negative_over], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text preprocesing\n",
    "def get_text_processing(text):\n",
    "    stpword = stopwords.words('english')\n",
    "    no_punctuation = [char for char in text if char not in string.punctuation]\n",
    "    no_punctuation = ''.join(no_punctuation)\n",
    "    return ' '.join([word for word in no_punctuation.split() if word.lower() not in stpword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text', 'airline_sentiment']]\n",
    "df['text'] = df['text'].apply(get_text_processing)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummies\n",
    "df_dummies = pd.get_dummies(df['airline_sentiment'])\n",
    "df_ranked = df.drop(['airline_sentiment'], axis=1, inplace=True)\n",
    "df_complete = pd.concat([df, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train, test split\n",
    "\n",
    "X = df_complete[\"text\"].values\n",
    "y = df_complete.drop(\"text\", axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization\n",
    "\n",
    "vect = CountVectorizer()\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test1 = vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test1 = tfidf.transform(X_test1)\n",
    "X_train = X_train.toarray()\n",
    "X_test1 = X_test1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=12673, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=4000, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=500, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=3, activation=\"softmax\"))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the model\n",
    "\n",
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=256,\n",
    "    epochs=2,\n",
    "    validation_data=(X_test1, y_test),\n",
    "    verbose=1,\n",
    "    callbacks=early_stop,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model evaluation\n",
    "\n",
    "model_score = model.evaluate(X_test, y_test, batch_size=64, verbose=1)\n",
    "print(\"Test accuracy:\", model_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model predictions\n",
    "df_kaggel['text'] = df_kaggel['text'].apply(get_text_processing)\n",
    "test_ds  = df_kaggel['text']\n",
    "test_feature = vect.transform(np.array(test_ds.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(test_feature)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggel['our_sent'] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rating_categories = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "df_kaggel['our_sent'] = df_kaggel['our_sent'].map(dict_rating_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_model(text, df):\n",
    "    \"\"\"text argument comes from the df passed to the function\"\"\"\n",
    "    \n",
    "    \n",
    "    #text = df['text']\n",
    "    #model predictions\n",
    "    text = text.apply(get_text_processing)\n",
    "    test_ds  = text\n",
    "    test_feature = vect.transform(np.array(test_ds.ravel()))\n",
    "\n",
    "    predict = model.predict(test_feature)\n",
    "    predict = np.argmax(predict, axis=1)\n",
    "\n",
    "    df['our_sent'] = predict\n",
    "\n",
    "    dict_rating_categories = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "    df['our_sent'] = df['our_sent'].map(dict_rating_categories)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def quick_sentiment(text):\n",
    "    \"\"\"Returns sentiment for 1-2 tweets.\"\"\"\n",
    "    \n",
    "    text = pd.Series(text)\n",
    "    \n",
    "    #model predictions\n",
    "    text = text.apply(get_text_processing)\n",
    "    test_ds  = text\n",
    "    test_feature = vect.transform(np.array(test_ds.ravel()))\n",
    "\n",
    "    predict = model.predict(test_feature)\n",
    "    predict = np.argmax(predict, axis=1)\n",
    "    \n",
    "    dict_rating_categories = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "    predict = np.vectorize(dict_rating_categories.__getitem__)(predict)\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating convos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_host = \"localhost\"\n",
    "database_name = \"dbl_data_challenge\"\n",
    "database_user = \"admin\"\n",
    "database_pass = \"vZtbqKNXGz27cQCH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = psy.connect(\n",
    "    host = database_host,\n",
    "    database = database_name,\n",
    "    user = database_user,\n",
    "    password = database_pass\n",
    ")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "    SELECT tweetv2.full_text, tweetv2.user_id_str, tweetv2.timestamp_ms, aba_groups.id_str, aba_groups.aba_level, aba_groups.aba_id, aba_groups.conversation_id\n",
    "    FROM tweetv2, aba_groups\n",
    "    WHERE tweetv2.id_str = aba_groups.id_str\n",
    "    ORDER BY aba_groups.aba_id, aba_groups.aba_level\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating sentiment for ABA conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aba = pd.DataFrame(columns=['full_text', 'user_id_str','timestamp_ms', 'id_str', 'aba_level', 'aba_id', 'conversation_id'], data=cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_aba_sent = our_model(df_aba['full_text'], df_aba)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aba_sent = pd.read_csv('aba_sentiment.csv')\n",
    "\n",
    "dict_rating_categories_2 = {'negative':-1, 'neutral':0, 'positive':1}\n",
    "df_aba_sent['our_sent'] = df_aba_sent['our_sent'].map(dict_rating_categories_2)\n",
    "\n",
    "df_aba_sent = df_aba_sent.drop(['Unnamed: 0'],axis=1)\n",
    "df_aba_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_list=[]\n",
    "\n",
    "for aba_id, data in df_aba_sent.groupby(\"aba_id\"): \n",
    "    aba_group = df_aba_sent[df_aba_sent[\"aba_id\"] == aba_id]\n",
    "    \n",
    "    for level, row in aba_group.groupby(\"aba_level\"): \n",
    "        if level==1:\n",
    "            sent_1 = float(row['our_sent'])\n",
    "        elif level==3:\n",
    "            sent_3 = float(statistics.mean(row['our_sent']))\n",
    "         \n",
    "\n",
    "    if sent_1 == -1:\n",
    "        if sent_3 < -.5:\n",
    "            change_list.append('no_change')\n",
    "        elif -.5 <= sent_3 <= 0:\n",
    "            change_list.append('minor_positive_change')\n",
    "        elif sent_3 > 0:\n",
    "            change_list.append('positive_change')\n",
    "\n",
    "    if sent_1 == 1:\n",
    "        if 0 <= sent_3 <= .5:\n",
    "            change_list.append('minor_negative_change')\n",
    "        elif sent_3 < 0:\n",
    "            change_list.append('negative_change')\n",
    "        elif sent_3 > .5:\n",
    "            change_list.append('no_change')\n",
    "\n",
    "    if sent_1 == 0:\n",
    "        if .34 < sent_3 < .67: \n",
    "            change_list.append('minor_positive_change')\n",
    "        elif -.34 < sent_3 < -.67:\n",
    "            change_list.append('minor_negative_change')\n",
    "        elif -.34 <= sent_3 <= .34:\n",
    "            change_list.append('no_change')\n",
    "        elif sent_3 >= .67:\n",
    "            change_list.append('positive_change')\n",
    "        elif sent_3 <= .67:\n",
    "            change_list.append('negative_change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict_rating_categories_2_reverse = {-1:'negative', 0:'neutral', 1:'positive',\n",
    "    'positive_change':'positive_change','negative_change':'negative_change','no_change':'no_change','minor_positive_change':'minor_positive_change','minor_negative_change':'minor_negative_change'}\n",
    "\n",
    "df_aba_sent.loc[df_aba_sent['aba_level']==2,'our_sent'] = change_list\n",
    "\n",
    "\n",
    "df_aba_sent['our_sent'] = df_aba_sent['our_sent'].map(dict_rating_categories_2_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_aba_sent.to_csv('df_aba_sent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating sentiment for root conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "    SELECT tweetv2.full_text, tweetv2.timestamp_ms, tweetv2.user_id_str, root_groups.id_str, root_groups.root_level, root_groups.root_id\n",
    "    FROM tweetv2, root_groups\n",
    "    WHERE tweetv2.id_str = root_groups.id_str\n",
    "    ORDER BY root_groups.root_id, root_groups.root_level\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root = pd.DataFrame(columns=['full_text','timestamp_ms', 'user_id_str', 'id_str', 'root_level', 'root_id'], data=cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_root_sent = our_model(df_root['full_text'], df_root)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root_sent.to_csv('df_root_sent.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
